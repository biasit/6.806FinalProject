{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPf3QuqOCW/4CLg3D2QPZ+k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8WOOKrIAnPoZ"},"source":["### Task Oriented Dialogue as Dataflow: Structured Seq2Seq Generation\n","\n","This notebook walks through the main steps for running all code for our project."]},{"cell_type":"markdown","metadata":{"id":"EJsLFRKpnJTl"},"source":["### Setup\n","setup.sh will install the necessary packages for working with the task_oriented_dialogue_as_dataflow_synthesis dataset."]},{"cell_type":"code","metadata":{"id":"MKpv4bv_nHgn"},"source":["!bash setup.sh"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LLxXrPJcnoc6"},"source":["get_output.sh runs the task_oriented_dialogue_as_dataflow_synthesis code to get\n","the source and target data."]},{"cell_type":"code","metadata":{"id":"v8bbcKQqnqHf"},"source":["!bash data_preprocessing/getoutput.sh"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yGwqv_ysnsMB"},"source":["### Data Preprocessing\n","All of our data preprocessing occurs in data_processing/process_data_combined.py. During the preprocessing phase, we also compute the retrieval mechanism via SentenceBert. Running process_data_combined.py will process and save our data for future use."]},{"cell_type":"code","metadata":{"id":"V9i6_uMon9mp"},"source":["!python3 data_processing/process_data_combined.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-fHAV2vc0PVr"},"source":["We load in our original train data and our data with the augmented source and retrieval mechanisms."]},{"cell_type":"code","metadata":{"id":"MW7jU6Nrz-aC"},"source":["# Original data\n","data_dir = \"./model_input\"\n","train_set_path = os.path.join(data_dir,'train_set.pkl')\n","val_set_path = os.path.join(data_dir,'val_set.pkl')\n","train_set = load_dataflow(train_set_path)\n","val_set = laod_dataflow(val_set_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-XfGHw20saa"},"source":["# Data augmented by retrieval mechanism\n","train_set_path = os.path.join(data_dir,'train_set_retrieval.pkl')\n","val_set_path = os.path.join(data_dir,'val_set_retrieval.pkl')\n","train_set_retrieval = load_dataflow(train_set_path)\n","val_set_retrieval = laod_dataflow(val_set_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rfP9wCRhywWq"},"source":["### Models \n","Here, we define, train, and run decoding on our models as desired."]},{"cell_type":"code","metadata":{"id":"3g1tgIbjy3_u","executionInfo":{"status":"ok","timestamp":1621581616140,"user_tz":300,"elapsed":73,"user":{"displayName":"Tom B","photoUrl":"","userId":"12902661183272994043"}}},"source":["from train_helper import setup_and_start_training, load_model_from_save \n","from decoder import store_model_predictons\n","\n","# Determine whether we should train or not\n","train = True"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nm1Ev3xrzpfu"},"source":["# All models use the same encoder and Seq2Seq structure\n","from models import Seq2Seq, Encoder\n","\n","# Global variables defines hyper parameters\n","from global_variables import HIDDEN_SIZE, EMBED_SIZE, DEVICE, MODEL_FOLDER"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5AsT_OFi132M"},"source":["#### Baseline Seq2Seq\n","As described in the paper, the baseline Seq2Seq is a simple Encoder-Decoder architecture with Bahdanau attention."]},{"cell_type":"code","metadata":{"id":"LHUxekGry7_g"},"source":["from models import Decoder\n","encoder = Encoder(len(train_set.src_vocab), EMBED_SIZE, HIDDEN_SIZE) \n","decoder = Decoder(len(train_set.trg_vocab), EMBED_SIZE, HIDDEN_SIZE)\n","seq2seq = Seq2Seq(encoder, decoder).to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1-8oOF61ZzQ"},"source":["# Train or load model\n","model_save_name = 'seq2seq.pt'\n","if train_model:\n","    setup_and_start_training(seq2seq, train_set, val_set, model_save_name)\n","else:\n","    load_model_from_save(seq2seq, model_save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdQu-pAZ2-qX"},"source":["# Run decoding on validation set\n","save_name = 'seq2seq'\n","store_model_predictions(seq2seq, val_set, save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bCcdui3n2EGa"},"source":["#### Baseline CopyNet\n","To implement CopyNet, we created a Decoder with a copy mechanism."]},{"cell_type":"code","metadata":{"id":"qbtnu-5l2Gdc"},"source":["from models import CopyNetDecoder\n","encoder = Encoder(len(train_set.src_vocab), EMBED_SIZE, HIDDEN_SIZE) \n","decoder = CopyNetDecoder(len(train_set.trg_vocab), EMBED_SIZE, HIDDEN_SIZE)\n","copynet = Seq2Seq(encoder, decoder).to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"olrPNlTW2vXO"},"source":["# Train or load model\n","model_save_name = 'copynet.pt'\n","if train_model:\n","    setup_and_start_training(copynet, train_set, val_set, model_save_name)\n","else:\n","    load_model_from_save(copynet, model_save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtFyqhW73VRB"},"source":["# Run decoding on validation set\n","save_name = 'copynet'\n","store_model_predictions(copynet, val_set, save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-gXrD3U33dA7"},"source":["#### CopyNet + Retrieval\n","Because our data preprocessing pipeline automatically appended retrieved sentences to our source set, we rerun the same copynet model but on the new dataset."]},{"cell_type":"code","metadata":{"id":"eO8YD-RS3dA8"},"source":["encoder = Encoder(len(train_set.src_vocab), EMBED_SIZE, HIDDEN_SIZE) \n","decoder = CopyNetDecoder(len(train_set.trg_vocab), EMBED_SIZE, HIDDEN_SIZE)\n","copynetWithRetrieval = Seq2Seq(encoder, decoder).to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulVVulwF3dA8"},"source":["# Train or load model\n","model_save_name = 'copynetWithRetrieval.pt'\n","if train_model:\n","    setup_and_start_training(copynetWithRetrieval, train_set_retrieval, \n","                             val_set_retrieval, model_save_name)\n","else:\n","    load_model_from_save(copynetWithRetrieval, model_save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lkaJb3Rs3dA8"},"source":["# Run decoding on validation set\n","save_name = 'copynetWithRetrieval'\n","store_model_predictions(copynetWithRetrieval, val_set_retrieval, save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j0HxVVtm4JHR"},"source":["#### CopyNet + Attention\n","We modified the CopyNet decoder such that it used Bahdanau attention."]},{"cell_type":"code","metadata":{"id":"JzV9aq9W4JHS"},"source":["from models import CopyNetDecoderWithAttention\n","encoder = Encoder(len(train_set.src_vocab), EMBED_SIZE, HIDDEN_SIZE) \n","decoder = CopyNetDecoderWithAttention(len(train_set.trg_vocab), EMBED_SIZE, HIDDEN_SIZE)\n","copynetWithAttention = Seq2Seq(encoder, decoder).to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPtoCADf4JHS"},"source":["# Train or load model\n","model_save_name = 'copynetWithAttention.pt'\n","if train_model:\n","    setup_and_start_training(copynetWithAttention, train_set, val_set, model_save_name)\n","else:\n","    load_model_from_save(copynetWithAttention, model_save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ffdpvm-t4JHS"},"source":["# Run decoding on validation set\n","save_name = 'copynetWithAttention'\n","store_model_predictions(copynetWithAttention, val_set, save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XLH1REka4oNz"},"source":["#### CopyNet + Attention + Retrieval\n","We provide a version of CopyNet with Attention and Retrieval."]},{"cell_type":"code","metadata":{"id":"3B1b3Bbg4oN2"},"source":["encoder = Encoder(len(train_set.src_vocab), EMBED_SIZE, HIDDEN_SIZE) \n","decoder = CopyNetDecoderWithAttention(len(train_set.trg_vocab), EMBED_SIZE, HIDDEN_SIZE)\n","copynetWithAttentionAndRetrieval = Seq2Seq(encoder, decoder).to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKvcl-jF4oN2"},"source":["# Train or load model\n","model_save_name = 'copynetWithAttentionAndRetrieval.pt'\n","if train_model:\n","    setup_and_start_training(copynetWithAttentionAndRetrieval, train_set_retrieval, \n","                             val_set_retrieval, model_save_name)\n","else:\n","    load_model_from_save(copynetWithAttentionAndRetrieval, \n","                         model_save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ntcgI_Ov4oN2"},"source":["# Run decoding on validation set\n","save_name = 'copynetWithAttentionAndRetrieval'\n","store_model_predictions(copynetWithAttentionAndRetrieval, val_set_retrieval, \n","                        save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KRi67Pau5NOe"},"source":["#### Transformer Encoder + CopyNet Decoder\n","We attempted to incorporate a transformer encoder into the model. This was as follows."]},{"cell_type":"code","metadata":{"id":"F8FRtfPH5bzm"},"source":["from train_helper import CustomTransformerEncoder\n","encoder = CustomTransformerEncoder(EMBED_SIZE, vocab_size=len(train_set.src_vocab)) \n","decoder = CopyNetDecoder(len(train_set.trg_vocab), EMBED_SIZE, HIDDEN_SIZE)\n","transformerCopynet = Seq2Seq(encoder, decoder).to(DEVICE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vYMnPe3W5W2L"},"source":["# Train or load model\n","model_save_name = 'transformerCopynet.pt'\n","if train_model:\n","    setup_and_start_training(transformerCopynet, train_set, \n","                             val_set, model_save_name)\n","else:\n","    load_model_from_save(transformerCopynet, \n","                         model_save_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8j2qGHUl6Iza"},"source":["# Run decoding on validation set\n","save_name = 'transformerCopynet'\n","store_model_predictions(transformerCopynet, val_set, \n","                        save_name)"],"execution_count":null,"outputs":[]}]}